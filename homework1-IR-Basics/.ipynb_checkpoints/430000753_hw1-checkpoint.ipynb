{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2020\n",
    "\n",
    "\n",
    "# Homework 1:  Information Retrieval Basics\n",
    "\n",
    "### 100 points [7% of your final grade]\n",
    "\n",
    "### Due: January 31 (Friday) by 11:59pm\n",
    "\n",
    "*Goals of this homework:* In this homework you will get first hand experience building a text-based mini search engine. In particular, there are three main learning objectives: (i) the basics of tokenization (e.g. stemming, case-folding, etc.) and its effect on information retrieval; (ii) basics of index building and Boolean retrieval; and (iii) basics of the Vector Space model and ranked retrieval.\n",
    "\n",
    "*Submission instructions (eCampus):* To submit your homework, rename this notebook as `UIN_hw1.ipynb`. For example, my homework submission would be something like `555001234_hw1.ipynb`. Submit this notebook via eCampus (look for the homework 1 assignment there). Your notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so). So please run all the cells for us, and then submit.\n",
    "\n",
    "*Late submission policy:* For this homework, you may use as many late days as you like (up to the 5 total allotted to you).\n",
    "\n",
    "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
    "\n",
    "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
    "\n",
    "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset is collected from Quizlet (https://quizlet.com), a website where users can generated their own flashcards. Each flashcard generated by a user is made up of an entity on the front and a definition describing or explaining the entity correspondingly on the back. We treat entities on each flashcard's front as the queries and the definitions on the back of flashcards as the documents. Definitions (documents) are relevant to an entity (query) if the definitions are from the back of the entity's flashcard; otherwise definitions are not relevant. **In this homework, queries and entities are interchangeable as well as documents and definitions.**\n",
    "\n",
    "The format of the dataset is like this:\n",
    "\n",
    "**query \\t document id \\t document**\n",
    "\n",
    "Examples:\n",
    "\n",
    "decision tree\t\\t 27946 \\t\tshow complex processes with multiple decision rules.  display decision logic (if statements) as set of (nodes) questions and branches (answers).\n",
    "\n",
    "where \"decision tree\" is the entity in the front of a flashcard and \"show complex processes with multiple decision rules.  display decision logic (if statements) as set of (nodes) questions and branches (answers).\" is the definition on the flashcard's back and \"27946\" is the id of the definition. Naturally, this document is relevant to the query.\n",
    "\n",
    "false positive rate\t\\t 686\t\\t fall-out; probability of a false alarm\n",
    "\n",
    "where document 686 is not relevant to query \"decision tree\" because the entity of \"fall-out; probability of a false alarm\" is \"false positive rate\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Parsing (20 points)\n",
    "\n",
    "First, you should tokenize documents (definitions) using **whitespaces and punctuations as delimiters**. Your parser needs to also provide the following three pre-processing options:\n",
    "* Remove stop words: use nltk stop words list (from nltk.corpus import stopwords)\n",
    "* Stemming: use [nltk Porter stemmer](http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter)\n",
    "* Remove any other strings that you think are less informative or nosiy.\n",
    "\n",
    "Please note that you should stick to the stemming package listed above. Otherwise, given the same query, the results generated by your code can be different from others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration options\n",
    "remove_stopwords = True\n",
    "use_stemming = True\n",
    "remove_otherNoise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize required data structures\n",
    "\n",
    "# contains the documents indexed by their  ids\n",
    "# list with 2 fields, [0] -> definition [1] -> Entitiy\n",
    "documents = {}\n",
    "\n",
    "# document tokens indexed by their ids\n",
    "# to avoid redundant processing\n",
    "doc_tokens = {}\n",
    "\n",
    "Total_document_length = 0\n",
    "# inverted index for our corpus\n",
    "inverted_index = {}\n",
    "\n",
    "# word frequency for ranking the doucments\n",
    "# 0 -> term frequency in the corpus\n",
    "word_frequency = {}\n",
    "\n",
    "# prepare a vocabulary index for the column id of individual words\n",
    "vocab_id_table = {}\n",
    "vocab_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_stopwords =  True  use_stemmer =  True  remove noise =  True  ==> 9741\n",
      "Time taken to parse dataset : 8.570852756500244\n"
     ]
    }
   ],
   "source": [
    "# Your parser function here. It will take the three option variables above as the parameters\n",
    "start = time.time()\n",
    "\n",
    "remove_punct = '!\"#$&\\'()*+,./;:<=>?@[\\\\]^`{|}~%_-'\n",
    "table = str.maketrans(remove_punct,' '*len(remove_punct), '' )\n",
    "\n",
    "# Stem the words user Porter's Algorithm\n",
    "if use_stemming == True:\n",
    "    myStemmer = PorterStemmer()\n",
    "\n",
    "with open('homework_1_data.txt', 'r', encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        doc = line.split('\\t')\n",
    "        curr_doc_id = int(doc[1])\n",
    "\n",
    "        # ids converted to integer for faster matching\n",
    "        documents[curr_doc_id] = [doc[2],doc[0]]\n",
    "\n",
    "        doc_without_punct = doc[2].translate(table)\n",
    "\n",
    "        words = doc_without_punct.split()\n",
    "        Total_document_length += len(words)\n",
    "\n",
    "        # the set of seen words for each document\n",
    "        for i in range(len(words)):\n",
    "\n",
    "            # handling leading and trailing hyphens\n",
    "            words[i] = words[i].strip(\"-\")\n",
    "\n",
    "            # Case Folding\n",
    "            words[i] = words[i].lower()            \n",
    "\n",
    "            if use_stemming == True:\n",
    "                words[i] = myStemmer.stem(words[i])\n",
    "\n",
    "            if remove_otherNoise == True:\n",
    "                remove_digits = '0123456789'\n",
    "                digit_table = str.maketrans('','',remove_digits)\n",
    "                words[i] = words[i].translate(digit_table )\n",
    "\n",
    "            # is this word in our dictionary already?\n",
    "            if words[i] in inverted_index:\n",
    "\n",
    "                # add the current document id to that word's document list\n",
    "                inverted_index[words[i]].add(curr_doc_id)\n",
    "\n",
    "            # seeing the word for the first time\n",
    "            else:\n",
    "                inverted_index[words[i]] = set({curr_doc_id})\n",
    "\n",
    "                # returns the id for individual words\n",
    "                vocab_id_table[words[i]] = vocab_id\n",
    "                vocab_id += 1\n",
    "\n",
    "        # store the tokens for this document\n",
    "        doc_tokens[curr_doc_id] = words\n",
    "\n",
    "# remove stopwrods directly from the inverted index\n",
    "if remove_stopwords == True:\n",
    "    for stopword in stopwords.words('english'):\n",
    "        if stopword in inverted_index:\n",
    "            del inverted_index[stopword]\n",
    "            del vocab_id_table[stopword]\n",
    "\n",
    "\n",
    "# total number of documents in the corpus\n",
    "N = len(doc_tokens)\n",
    "\n",
    "avgdl = Total_document_length/N\n",
    "\n",
    "print(\"remove_stopwords = \", remove_stopwords, \" use_stemmer = \", use_stemming, \" remove noise = \", remove_otherNoise,\" ==>\", len(inverted_index))\n",
    "end = time.time()\n",
    "print(\"Time taken to parse dataset :\",end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Once you have your parser working, you should report here the size of your dictionary under the four cases. That is, how many unique tokens do you have with stemming on and casefolding on? And so on. You should fill in the following\n",
    "\n",
    "* None of pre-processing options      = 16276\n",
    "* remove stop words       = 16136\n",
    "* remove stop words + stemming       = 10242\n",
    "* remove stop words + stemming  + remove other noise     = 9741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Boolean Retrieval (30 points)\n",
    "\n",
    "In this part you build an inverted index to support Boolean retrieval. We only require your index to support AND queries. In other words, your index does not have to support OR, NOT, or parentheses. Also, we do not explicitly expect to see AND in queries, e.g., when we query **relational model**, your search engine should treat it as **relational** AND **model**.\n",
    "\n",
    "Search for the queries below using your index and print out matching documents (for each query, print out 5 matching documents):\n",
    "* relational database\n",
    "* garbage collection\n",
    "* retrieval model\n",
    "\n",
    "Please use the following format to present your results:\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## query processing and setup\n",
    "\n",
    "queries = ['relational database','garbage collection','retrieval model' ]\n",
    "\n",
    "query_tokens = []\n",
    "\n",
    "remove_punct = '!\"#$&\\'()*+,./;:<=>?@[\\\\]^`{|}~%_-'\n",
    "q_table = str.maketrans(remove_punct,' '*len(remove_punct), '' )\n",
    "\n",
    "# Stem the words user Porter's Algorithm\n",
    "if use_stemming == True:\n",
    "    myStemmer = PorterStemmer()\n",
    "\n",
    "for query in queries:\n",
    "    # sanity check for punctuations in query\n",
    "    # keeping inline with our parsing function\n",
    "    \n",
    "    query_without_punctuations = query.translate(q_table)\n",
    "    query_words = query_without_punctuations.split()\n",
    "\n",
    "    for j in range(len(query_words)):\n",
    "\n",
    "        # handling leading and trailing hyphens\n",
    "        query_words[j] = query_words[j].strip(\"-\")\n",
    "\n",
    "        # Case Folding\n",
    "        query_words[j] = query_words[j].lower()\n",
    "\n",
    "        if use_stemming == True:\n",
    "            query_words[j] = myStemmer.stem(query_words[j])\n",
    "\n",
    "        if remove_otherNoise == True:\n",
    "            remove_digits = '0123456789'\n",
    "            q_digit_table = str.maketrans('','',remove_digits)\n",
    "            query_words[j] = query_words[j].translate(q_digit_table )\n",
    "\n",
    "    # remove stopwords separately\n",
    "    if remove_stopwords == True:\n",
    "        for k in reversed(range(len(query_words))):\n",
    "            if query_words[k] in stopwords.words('english'):\n",
    "                del query_words[k]\n",
    "        \n",
    "    # add the tokens for reference\n",
    "    query_tokens.append(query_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['relational database', 'garbage collection', 'retrieval model']\n",
      "[['relat', 'databas'], ['garbag', 'collect'], ['retriev', 'model']]\n"
     ]
    }
   ],
   "source": [
    "print(queries)\n",
    "print(query_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Part 2: Boolean Retrieval ~~~\n",
      "\n",
      "query:  relational database \n",
      "\n",
      "Total Number of retrievals:  237 \n",
      "\n",
      "result  1 :\n",
      "entity:  relational database\n",
      "definitiion id:  28160\n",
      "definition:  a group of related databases associated by a key, or a common identifying (qualitative) characteristic.\n",
      "\n",
      "result  2 :\n",
      "entity:  relational databases\n",
      "definitiion id:  5121\n",
      "definition:  - relational databases store data in 2-dimensional tables - the tables establish connections between the different entities we want to model - the &\"relational&\" in relational database (rdb) comes from the concept of a relation in set theory.\n",
      "\n",
      "result  3 :\n",
      "entity:  relational databases\n",
      "definitiion id:  5122\n",
      "definition:  relational databases use two or more tables linked together (to form a relationship). relational databases do not store all the data in the same table. repeated data is moved into it's own table as shown in the image below:\n",
      "\n",
      "result  4 :\n",
      "entity:  relational database\n",
      "definitiion id:  28163\n",
      "definition:  a relational database is represented by a schema with two components ✤ relations s = {r1, r2, ..., rn} ✤ integrity constraints ic = {ic1, ic2, ..., icm}\n",
      "\n",
      "result  5 :\n",
      "entity:  relational database\n",
      "definitiion id:  28164\n",
      "definition:  table-based organization for a database in which queries can be specified using relational database operators\n",
      "\n",
      "query:  garbage collection \n",
      "\n",
      "Total Number of retrievals:  8 \n",
      "\n",
      "result  1 :\n",
      "entity:  garbage collection\n",
      "definitiion id:  21576\n",
      "definition:  a class instance is explicitly created by the java code and after use it is automatically destroyed by garbage collection for memory management.\n",
      "\n",
      "result  2 :\n",
      "entity:  garbage collection\n",
      "definitiion id:  21550\n",
      "definition:  automatic memory management is made possible by garbage collection in .net framework. when a class object is created at runtime, certain memory space is allocated to it in the heap memory. however, after all the actions related to the object are completed in the program, the memory space allocated to it is a waste as it cannot be used. in this case, garbage collection is very useful as it automatically releases the memory space after it is no longer required.\n",
      "\n",
      "result  3 :\n",
      "entity:  garbage collection\n",
      "definitiion id:  21553\n",
      "definition:  garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result  4 :\n",
      "entity:  garbage collection\n",
      "definitiion id:  21554\n",
      "definition:  there is a third phase of 2pc called garbage collection. replicas must retain records of past transactions, just in case leader fails. in practice, leader periodically tells replicas to garbage collect.\n",
      "\n",
      "result  5 :\n",
      "entity:  garbage collection\n",
      "definitiion id:  21555\n",
      "definition:  when data is no longer referable (i.e., there are no remaining references to that data available for executable code), it is &\"garbage collected&\" and will be destroyed at some later point in time\n",
      "\n",
      "query:  retrieval model \n",
      "\n",
      "Total Number of retrievals:  13 \n",
      "\n",
      "result  1 :\n",
      "entity:  information processing\n",
      "definitiion id:  17315\n",
      "definition:  taking in information, figuring out whats important, storing and retrieving processes  computer model= same software\n",
      "\n",
      "result  2 :\n",
      "entity:  physical design\n",
      "definitiion id:  10341\n",
      "definition:  -translate logical model into technical specification for strong/retrieving data -store data to achieve efficiency and quality\n",
      "\n",
      "result  3 :\n",
      "entity:  data model\n",
      "definitiion id:  6983\n",
      "definition:  - a collection of concepts that can be used to describe the structure of a database - describes the structure - dbms is based on a data model   structure of data model:  - records - types - relationships - constraints - basic operations (specifying retrievals and updates)  types of data models: - high-level (conceptual i.e. er) - low level (physical i.e. xml) - implementation (representational) combines conceptual and physical i.e. relational model - nosql data models i.e. column, key-value, document stores\n",
      "\n",
      "result  4 :\n",
      "entity:  web browser\n",
      "definitiion id:  17705\n",
      "definition:  -a software application used to locate, retrieve, and display content on the world wide web, including web pages, images, video, and other files -as a client/server model, the browser is the client on a computer that contacts the web server and requests information. the web server sends the information back to the web brows\n",
      "\n",
      "result  5 :\n",
      "entity:  online analytical processing\n",
      "definitiion id:  19727\n",
      "definition:  tools for retrieving, processing, and modelling data from the data warehouse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Boolean retreival\n",
    "#\n",
    "\n",
    "print(\"~~~ Part 2: Boolean Retrieval ~~~\")\n",
    "print(\"\")\n",
    "\n",
    "boolean_results_query = []\n",
    "for query_id in range(len(queries)):\n",
    "\n",
    "    if query_tokens[query_id]:\n",
    "        res_Boolean = inverted_index[query_tokens[query_id][0]]\n",
    "        for word in query_tokens[query_id][1:]:\n",
    "            res_Boolean = res_Boolean.intersection(inverted_index[word])\n",
    "\n",
    "    boolean_results_query.append(res_Boolean)\n",
    "    # Print Results\n",
    "    print(\"query: \",queries[query_id], \"\\n\")\n",
    "    print(\"Total Number of retrievals: \", len(res_Boolean), \"\\n\")  \n",
    "    for r in range(5):\n",
    "        print(\"result \",r+1,\":\")\n",
    "        print(\"entity: \",documents[list(res_Boolean)[r]][1])\n",
    "        print(\"definitiion id: \",list(res_Boolean)[r])\n",
    "        print(\"definition: \",documents[list(res_Boolean)[r]][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "Could your boolean search engine find relevant documents for these queries? What is the impact of the three pre-processing options? Do they improve your search quality?\n",
    "\n",
    "Answer:\n",
    "Yes, boolean search engine was able to retrieve relevant documents for the queries when the pre-processing options were applied.\n",
    "It failed to retrieve documents for the query 'retrieval model' when all pre-processing options were disabled.\n",
    "It suggests that the initial preprocessing (stemming, removal of stopwords and noise, handling of punctuations etc) indeed helps in improving the retrieval quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Ranking Documents (50 points) \n",
    "\n",
    "In this part, your job is to rank the documents that have been retrieved by the Boolean Retrieval component in Part 2, according to their relevance with each query.\n",
    "\n",
    "### A: Ranking with simple sums of TF-IDF scores (15 points) \n",
    "For a multi-word query, we rank documents by a simple sum of the TF-IDF scores for the query terms in the document.\n",
    "TF is the log-weighted term frequency $1+log(tf)$; and IDF is the log-weighted inverse document frequency $log(\\frac{N}{df})$\n",
    "\n",
    "**Output:**\n",
    "For each given query in Part 2, you should just rank the documents retrieved by your boolean search. You only need to output the top-5 results plus the TF-IDF sum score of each of these documents. Please use the following format to present your results:\n",
    "\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* score: 0.1\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## prepare vector space for documents\n",
    "#\n",
    "\n",
    "doc_vectors = np.zeros((N,vocab_id))\n",
    "IDF = {}\n",
    "IDF_BM25 = {}\n",
    "\n",
    "for word,word_id in vocab_id_table.items():\n",
    "    nq = len(inverted_index[word])\n",
    "    IDF[word] = math.log10(N/nq)\n",
    "    IDF_BM25[word] = math.log10((N - nq + 0.5)/(nq + 0.5))\n",
    "\n",
    "for this_doc_id,this_doc_tokens in doc_tokens.items():\n",
    "\n",
    "    # count the number of occurences for ech word        \n",
    "    term_freq = Counter(this_doc_tokens)\n",
    "    # for each word and its count\n",
    "    for term,count in term_freq.items():\n",
    "        if remove_stopwords == True and term in stopwords.words('english'):\n",
    "            continue\n",
    "        tf = 1 + math.log10(count)\n",
    "        # documents are rows and words are columns\n",
    "        doc_vectors[this_doc_id][vocab_id_table[term]] += (tf * IDF[term])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Part 3A: Ranking with simple sums of TF-IDF scores ~~~\n",
      "\n",
      "query:  relational database \n",
      "\n",
      "result  1 :\n",
      "score:  4.718083875753986\n",
      "entity:  relational algebra\n",
      "definition id:  7156\n",
      "definition:  - a theoretical language with operations that work on one or more relations to define another relation without changing the original relation(s)  - relation-at-a-time (or set) language in which all tuples, possibly from several relations, are manipulated in one statement without looping  relational algebra, first created by edgar f. codd while at ibm, is a family of algebras with a well-founded semantics used for modelling the data stored in relational databases, and defining queries on it.  the main application of relational algebra is providing a theoretical foundation for relational databases, particularly query languages for such databases, chief among which is sql.\n",
      "\n",
      "result  2 :\n",
      "score:  4.358466421269945\n",
      "entity:  relational database\n",
      "definition id:  28378\n",
      "definition:  a type of database system where data is stored in  tables related by common fields. a relational database is the most common type of database used with a personal computer. similar data is held in a table (e.g. students, courses, books, instructors) and tables are related through a common field (a field that is in more than one table) microsoft access and corel paradox are both relational database management systems.\n",
      "\n",
      "result  3 :\n",
      "score:  4.122931371897405\n",
      "entity:  relational database\n",
      "definition id:  28254\n",
      "definition:  finite set of relations​. each relation consists of a schema and an instance​. database schema = set of relation schemas constraints among relations (inter-relational constraints)​. database instance = set of (corresponding) relation instances\n",
      "\n",
      "result  4 :\n",
      "score:  4.122931371897405\n",
      "entity:  relational model\n",
      "definition id:  741\n",
      "definition:  developed by ef codd of ibm in 19070, the relational model is based on mathematical set theory and represents data as independent relations. each relation (table) is conceptually represented as a two dimensional structure of intersecting rows and columns. the relations are related to each other through the sharing of common entity characteristics (values in columns). -to use an analogy, it produced an &\"automatic transmission&\" database to replace the &\"standard transmission&\" databases that preceded it. -describes a precise set of data manipulation constructs based on advanced mathematical concepts.\n",
      "\n",
      "result  5 :\n",
      "score:  4.018565736419941\n",
      "entity:  relational database\n",
      "definition id:  28326\n",
      "definition:  a dbms is characterized by the type of logical data model on which it is based. a data model is an abstract representation of the contents of a database. most new dbmss are called relational databases because they use the relational model developed by e. f. coddin 1970. the relational data model represents everything in the database as being stored in the forms of tables.\n",
      "\n",
      "query:  garbage collection \n",
      "\n",
      "result  1 :\n",
      "score:  6.530364437453885\n",
      "entity:  garbage collection\n",
      "definition id:  21553\n",
      "definition:  garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result  2 :\n",
      "score:  6.329663280206054\n",
      "entity:  garbage collection\n",
      "definition id:  21554\n",
      "definition:  there is a third phase of 2pc called garbage collection. replicas must retain records of past transactions, just in case leader fails. in practice, leader periodically tells replicas to garbage collect.\n",
      "\n",
      "result  3 :\n",
      "score:  6.329663280206054\n",
      "entity:  garbage collection\n",
      "definition id:  21550\n",
      "definition:  automatic memory management is made possible by garbage collection in .net framework. when a class object is created at runtime, certain memory space is allocated to it in the heap memory. however, after all the actions related to the object are completed in the program, the memory space allocated to it is a waste as it cannot be used. in this case, garbage collection is very useful as it automatically releases the memory space after it is no longer required.\n",
      "\n",
      "result  4 :\n",
      "score:  5.521120538966688\n",
      "entity:  garbage collection\n",
      "definition id:  21559\n",
      "definition:  garbage collection is a feature that automatically deletes unused memory that is no longer being referenced. you cannot force it but you can request it using system.gc() but you should never use that because it slows down your program heavily. once the system thinks an object it ready for collection, it will call finalize() on it which does final cleanup and prepares it do be collected\n",
      "\n",
      "result  5 :\n",
      "score:  4.865117100529037\n",
      "entity:  garbage collection\n",
      "definition id:  21576\n",
      "definition:  a class instance is explicitly created by the java code and after use it is automatically destroyed by garbage collection for memory management.\n",
      "\n",
      "query:  retrieval model \n",
      "\n",
      "result  1 :\n",
      "score:  4.292304706110251\n",
      "entity:  data model\n",
      "definition id:  6983\n",
      "definition:  - a collection of concepts that can be used to describe the structure of a database - describes the structure - dbms is based on a data model   structure of data model:  - records - types - relationships - constraints - basic operations (specifying retrievals and updates)  types of data models: - high-level (conceptual i.e. er) - low level (physical i.e. xml) - implementation (representational) combines conceptual and physical i.e. relational model - nosql data models i.e. column, key-value, document stores\n",
      "\n",
      "result  2 :\n",
      "score:  3.3370417172064877\n",
      "entity:  online analytical processing\n",
      "definition id:  19733\n",
      "definition:  a set of tools that provide advanced data analysis for retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result  3 :\n",
      "score:  3.3370417172064877\n",
      "entity:  online analytical processing\n",
      "definition id:  19731\n",
      "definition:  enable retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result  4 :\n",
      "score:  3.3370417172064877\n",
      "entity:  online analytical processing\n",
      "definition id:  19727\n",
      "definition:  tools for retrieving, processing, and modelling data from the data warehouse\n",
      "\n",
      "result  5 :\n",
      "score:  3.3370417172064877\n",
      "entity:  online analytical processing\n",
      "definition id:  19708\n",
      "definition:  olap - tools for retrieving, processing, and modeling data from the data warehouse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# hint: you could first call boolean retrieval function in part 2 to find possible relevant documents, \n",
    "# and then rank these documents in this part. Hence, you don't need to rank all documents.\n",
    "\n",
    "print(\"~~~ Part 3A: Ranking with simple sums of TF-IDF scores ~~~\")\n",
    "print(\"\")\n",
    "\n",
    "for query_id in range(len(queries)):\n",
    "\n",
    "    scores = []\n",
    "    for match_doc_id in boolean_results_query[query_id]:\n",
    "        doc_score = 0\n",
    "        \n",
    "        for keyword in set(query_tokens[query_id]):\n",
    "\n",
    "            # count the number of occurrence of this keyword in document\n",
    "            t_fd = doc_tokens[match_doc_id].count(keyword)\n",
    "            \n",
    "            tf = 1 + math.log10(t_fd)\n",
    "\n",
    "            # sum over all terms in query AND document\n",
    "            doc_score += (tf * IDF[keyword])\n",
    "            \n",
    "        # append the final document score for comparision\n",
    "        scores.append((doc_score,match_doc_id))\n",
    "\n",
    "\n",
    "    # Print Results\n",
    "    print(\"query: \",queries[query_id], \"\\n\")\n",
    "\n",
    "    r = 0 # top results to print\n",
    "    # replace with quickselect for larger corpuses\n",
    "    for score,doc_id in sorted(scores,reverse=True)[:5]:\n",
    "        r += 1 \n",
    "        print(\"result \",r,\":\")\n",
    "        print(\"score: \", score)\n",
    "        print(\"entity: \", documents[doc_id][1])\n",
    "        print(\"definition id: \", doc_id )\n",
    "        print(\"definition: \", documents[doc_id][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Ranking with vector space model with TF-IDF (15 points) \n",
    "\n",
    "**Cosine:** You should use cosine as your scoring function. \n",
    "\n",
    "**TFIDF:** For the document vectors, use the standard TF-IDF scores as introduced in A. For the query vector, use simple weights (the raw term frequency). For example:\n",
    "* query: troll $\\rightarrow$ (1)\n",
    "* query: troll trace $\\rightarrow$ (1, 1)\n",
    "\n",
    "**Output:**\n",
    "For each given query in Part 2, you should just rank the documents retrieved by your boolean search. You only need to output the top-5 documents plus the cosine score of each of these documents. Please use the following format to present your results:\n",
    "\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* score: 0.1\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......\n",
    "\n",
    "You can additionally assume that your queries will contain at most three words. Be sure to normalize your vectors as part of the cosine calculation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Part 3B: Ranking with vector space model with TF-IDF ~~~\n",
      "query:  relational database \n",
      "\n",
      "result  1 :\n",
      "score:  0.7537315690025447\n",
      "entity:  relational database\n",
      "definition id:  28227\n",
      "definition:  a database using the relational data model.\n",
      "\n",
      "result  2 :\n",
      "score:  0.6712815370258216\n",
      "entity:  relational database\n",
      "definition id:  28210\n",
      "definition:  a collection of related database tables\n",
      "\n",
      "result  3 :\n",
      "score:  0.6712815370258216\n",
      "entity:  relational model\n",
      "definition id:  771\n",
      "definition:  a database is a collection of relations or tables.\n",
      "\n",
      "result  4 :\n",
      "score:  0.6591374090355712\n",
      "entity:  relational database\n",
      "definition id:  28134\n",
      "definition:  a database including tables that are related to each other\n",
      "\n",
      "result  5 :\n",
      "score:  0.6005458659464757\n",
      "entity:  relational database\n",
      "definition id:  28205\n",
      "definition:  a database built using the relational database model\n",
      "\n",
      "~~~ Part 3B: Ranking with vector space model with TF-IDF ~~~\n",
      "query:  garbage collection \n",
      "\n",
      "result  1 :\n",
      "score:  0.7925773097508486\n",
      "entity:  garbage collector\n",
      "definition id:  4150\n",
      "definition:  the part of the operating system that performs garbage collection.\n",
      "\n",
      "result  2 :\n",
      "score:  0.48375611797464657\n",
      "entity:  memory safety\n",
      "definition id:  13115\n",
      "definition:  memory management handled differently such that there is garbage collection, prevent dangling pointer references.\n",
      "\n",
      "result  3 :\n",
      "score:  0.4705403015859057\n",
      "entity:  garbage collection\n",
      "definition id:  21576\n",
      "definition:  a class instance is explicitly created by the java code and after use it is automatically destroyed by garbage collection for memory management.\n",
      "\n",
      "result  4 :\n",
      "score:  0.4668666094857771\n",
      "entity:  garbage collection\n",
      "definition id:  21553\n",
      "definition:  garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result  5 :\n",
      "score:  0.4482011771844025\n",
      "entity:  garbage collection\n",
      "definition id:  21555\n",
      "definition:  when data is no longer referable (i.e., there are no remaining references to that data available for executable code), it is &\"garbage collected&\" and will be destroyed at some later point in time\n",
      "\n",
      "~~~ Part 3B: Ranking with vector space model with TF-IDF ~~~\n",
      "query:  retrieval model \n",
      "\n",
      "result  1 :\n",
      "score:  0.6521229582809138\n",
      "entity:  query language\n",
      "definition id:  9085\n",
      "definition:  used to update and retrieve data that is stored in a data model\n",
      "\n",
      "result  2 :\n",
      "score:  0.6055504960229509\n",
      "entity:  online analytical processing\n",
      "definition id:  19727\n",
      "definition:  tools for retrieving, processing, and modelling data from the data warehouse\n",
      "\n",
      "result  3 :\n",
      "score:  0.6040336434685005\n",
      "entity:  online analytical processing\n",
      "definition id:  19731\n",
      "definition:  enable retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result  4 :\n",
      "score:  0.48655906941985433\n",
      "entity:  online analytical processing\n",
      "definition id:  19708\n",
      "definition:  olap - tools for retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result  5 :\n",
      "score:  0.46456503967928964\n",
      "entity:  information processing\n",
      "definition id:  17315\n",
      "definition:  taking in information, figuring out whats important, storing and retrieving processes  computer model= same software\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## Vector Space Model\n",
    "#\n",
    "\n",
    "for query_id in range(len(queries)):\n",
    "\n",
    "    # generating the query vector\n",
    "    # count the number of occurences for each word        \n",
    "    term_freq = Counter(query_tokens[query_id])\n",
    "    query_vector = np.zeros(vocab_id)\n",
    "\n",
    "    # for each word and its count\n",
    "    for term,count in term_freq.items():\n",
    "        if remove_stopwords == True and term in stopwords.words('english'):\n",
    "            continue\n",
    "        tf = count\n",
    "        # documents are rows and words are columns\n",
    "        query_vector[vocab_id_table[term]] += (tf * IDF[term])\n",
    "\n",
    "    # cosine similairty calculation for each document\n",
    "    cos_similarity = np.zeros(N)\n",
    "\n",
    "    # TODO - optimize this function. Use numpy only.\n",
    "    for idx in boolean_results_query[query_id]:\n",
    "        cos_similarity[idx] = dot(doc_vectors[idx], query_vector)/(norm(doc_vectors[idx])*norm(query_vector))\n",
    "\n",
    "    # gets the top 5 in linear time\n",
    "    top5_index = np.argpartition(cos_similarity, -5)[-5:]\n",
    "\n",
    "    top5_vsm = []\n",
    "    for index in top5_index :\n",
    "        top5_vsm.append((cos_similarity[index ],index ))\n",
    "\n",
    "    # Print Results\n",
    "    print(\"~~~ Part 3B: Ranking with vector space model with TF-IDF ~~~\")\n",
    "    print(\"query: \",queries[query_id], \"\\n\")\n",
    "\n",
    "    r = 0 # top results to print\n",
    "    for score,doc_id in sorted(top5_vsm,reverse=True)[:5]:\n",
    "        r += 1 \n",
    "        print(\"result \",r,\":\")\n",
    "        print(\"score: \", score)\n",
    "        print(\"entity: \", documents[doc_id][1])\n",
    "        print(\"definition id: \", doc_id )\n",
    "        print(\"definition: \", documents[doc_id][0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Ranking with BM25 (20 points) \n",
    "Finally, let's try the BM25 approach for ranking. Refer to https://en.wikipedia.org/wiki/Okapi_BM25 for the specific formula. You could choose k_1 = 1.2 and b = 0.75 but feel free to try other options.\n",
    "\n",
    "**Output:**\n",
    "For each given query in Part 2, you should just rank the documents retrieved by your boolean search. You only need to output the top-5 documents plus the BM25 score of each of these documents. Please use the following format to present your results:\n",
    "\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* score: 0.1\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Part 3C: Ranking with BM25 ~~~\n",
      " \n",
      "query:  relational database \n",
      "\n",
      "result  1 :\n",
      "score:  6.1260855760953135\n",
      "entity:  relational database\n",
      "definition id:  28177\n",
      "definition:  relational database schema with data\n",
      "\n",
      "result  2 :\n",
      "score:  5.7111963476297145\n",
      "entity:  relational database\n",
      "definition id:  28205\n",
      "definition:  a database built using the relational database model\n",
      "\n",
      "result  3 :\n",
      "score:  5.642429950758306\n",
      "entity:  relational database\n",
      "definition id:  28210\n",
      "definition:  a collection of related database tables\n",
      "\n",
      "result  4 :\n",
      "score:  5.229555542655476\n",
      "entity:  relational database\n",
      "definition id:  28227\n",
      "definition:  a database using the relational data model.\n",
      "\n",
      "result  5 :\n",
      "score:  5.229555542655476\n",
      "entity:  data warehouse\n",
      "definition id:  4648\n",
      "definition:  -set of related databases  -hierarchy of data\n",
      "\n",
      "query:  garbage collection \n",
      "\n",
      "result  1 :\n",
      "score:  7.719557749327347\n",
      "entity:  garbage collector\n",
      "definition id:  4150\n",
      "definition:  the part of the operating system that performs garbage collection.\n",
      "\n",
      "result  2 :\n",
      "score:  6.225417059874523\n",
      "entity:  memory safety\n",
      "definition id:  13115\n",
      "definition:  memory management handled differently such that there is garbage collection, prevent dangling pointer references.\n",
      "\n",
      "result  3 :\n",
      "score:  4.69656244280916\n",
      "entity:  garbage collection\n",
      "definition id:  21554\n",
      "definition:  there is a third phase of 2pc called garbage collection. replicas must retain records of past transactions, just in case leader fails. in practice, leader periodically tells replicas to garbage collect.\n",
      "\n",
      "result  4 :\n",
      "score:  4.46344111929959\n",
      "entity:  garbage collection\n",
      "definition id:  21553\n",
      "definition:  garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result  5 :\n",
      "score:  4.336778562273045\n",
      "entity:  garbage collection\n",
      "definition id:  21576\n",
      "definition:  a class instance is explicitly created by the java code and after use it is automatically destroyed by garbage collection for memory management.\n",
      "\n",
      "query:  retrieval model \n",
      "\n",
      "result  1 :\n",
      "score:  5.299753370968803\n",
      "entity:  online analytical processing\n",
      "definition id:  19731\n",
      "definition:  enable retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result  2 :\n",
      "score:  4.999759641777038\n",
      "entity:  online analytical processing\n",
      "definition id:  19727\n",
      "definition:  tools for retrieving, processing, and modelling data from the data warehouse\n",
      "\n",
      "result  3 :\n",
      "score:  4.491297801373168\n",
      "entity:  online analytical processing\n",
      "definition id:  19708\n",
      "definition:  olap - tools for retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result  4 :\n",
      "score:  4.491297801373168\n",
      "entity:  query language\n",
      "definition id:  9085\n",
      "definition:  used to update and retrieve data that is stored in a data model\n",
      "\n",
      "result  5 :\n",
      "score:  4.076707801084385\n",
      "entity:  information processing\n",
      "definition id:  17315\n",
      "definition:  taking in information, figuring out whats important, storing and retrieving processes  computer model= same software\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## BM25\n",
    "#\n",
    "\n",
    "print(\"~~~ Part 3C: Ranking with BM25 ~~~\")\n",
    "print(\" \")\n",
    "\n",
    "b= 0.75\n",
    "k_1 = 1.2\n",
    "avgdl = Total_document_length/N\n",
    "\n",
    "for query_id in range(len(queries)):\n",
    "\n",
    "    bm25_scores  = []\n",
    "\n",
    "    for match_doc_id in boolean_results_query[query_id]:\n",
    "        bm25_doc_score = 0\n",
    "        D = len(documents[match_doc_id][0].split())\n",
    "\n",
    "        for keyword in set(query_tokens[query_id]):\n",
    "            # count the number of occurrence of this keyword in document\n",
    "            f_qi_D = doc_tokens[match_doc_id].count(keyword)\n",
    "            # saturation\n",
    "            saturation = f_qi_D * ( k_1 + 1 ) / (f_qi_D + k_1)\n",
    "            # document length normaliztion (B)\n",
    "            B = (1 - b) + ( b * D / avgdl)                \n",
    "            # sum over all terms in query AND document\n",
    "            bm25_doc_score += IDF_BM25[keyword] * saturation / B\n",
    "        bm25_scores.append((bm25_doc_score,match_doc_id))\n",
    "\n",
    "\n",
    "    # Print Results\n",
    "    print(\"query: \",queries[query_id], \"\\n\")\n",
    "\n",
    "    r = 0 # top results to print\n",
    "    for score,doc_id in sorted(bm25_scores,reverse=True)[:5]:\n",
    "        r += 1 \n",
    "        print(\"result \",r,\":\")\n",
    "        print(\"score: \", score)\n",
    "        print(\"entity: \", documents[doc_id][1])\n",
    "        print(\"definition id: \", doc_id )\n",
    "        print(\"definition: \", documents[doc_id][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Briefly discuss the differences you see between the three methods. Is there one you prefer?\n",
    "\n",
    "Answer: \n",
    "\n",
    "1. In the tf-idf weight scheme of ranking documents, each doc is basically represented by a vector of tf-idf weight.\n",
    "2. In the vector space model, using the cosine tf-idf weighting, documents are ranked according to the proximity of the document to the query. This modeled the similarity precisely.\n",
    "3. BM25 gives a score to the document. It theoritically should be giving robust results.\n",
    "\n",
    "Due to the specific nature of the dataset we are using here, the first method works best and is preferred here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Evaluation (10 points)\n",
    "Rather than just compare methods by pure observation, there are several metrics to evaluate the performance of an IR engine: Precision, Recall, MAP, NDCG, HitRate and so on. These all require a ground truth set of queries and documents with a notion of **relevance**. These ground truth judgments can be expensive to obtain, so we are cutting corners here and treating a flashcard's front and back as a \"relevant\" query-document pair.\n",
    "\n",
    "That is, if a document (definition) in your top-5 results is from the back of query's (entity's) flashcard, this document is regarded as relevant to the query (entity). This document is also called a hit in IR. Based on the ground-truth, you could calculate the metrics for the three ranking methods and provide the results like these:\n",
    "\n",
    "* metric: Precision@5\n",
    "* TF-IDF - score1\n",
    "* Vector Space Model with TF-IDF - score2\n",
    "* BM25 - score3\n",
    "\n",
    "You could pick any of the reasonable metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "## prepearing the relevant document list\n",
    "## as we have many documents for the same entities,\n",
    "## we first prepare the ground truth list from our data set\n",
    "## with this list, we will compare our results and count the intersections\n",
    "\n",
    "relevant_documents = {}\n",
    "\n",
    "for idx in range(len(documents)):\n",
    "    document = documents[idx]\n",
    "    \n",
    "    query = document[1]\n",
    "    query_without_punctuations = query.translate(q_table)\n",
    "    query_words = query_without_punctuations.split()\n",
    "\n",
    "    for i in range(len(query_words)):\n",
    "\n",
    "        # handling leading and trailing hyphens\n",
    "        query_words[i] = query_words[i].strip(\"-\")\n",
    "\n",
    "        # Case Folding\n",
    "        query_words[i] = query_words[i].lower()\n",
    "\n",
    "        if use_stemming == True:\n",
    "            query_words[i] = myStemmer.stem(query_words[i])\n",
    "\n",
    "        # TODO:\n",
    "        if remove_otherNoise == True:\n",
    "            remove_digits = '0123456789'\n",
    "            q_digit_table = str.maketrans('','',remove_digits)\n",
    "            query_words[i] = query_words[i].translate(q_digit_table )\n",
    "\n",
    "    # remove stopwords separately\n",
    "    if remove_stopwords == True:\n",
    "        for k in reversed(range(len(query_words))):\n",
    "            if query_words[k] in stopwords.words('english'):\n",
    "                del query_words[k]\n",
    "    \n",
    "    \n",
    "    # add the tokens for reference\n",
    "    if tuple(query_words) not in relevant_documents:\n",
    "        relevant_documents[tuple(query_words)] = set([idx])\n",
    "    else:\n",
    "        relevant_documents[tuple(query_words)].add(idx)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finally we will have our scores\n",
    "tfidf_relevant = 0\n",
    "vsm_relevant = 0\n",
    "bm25_relevant = 0\n",
    "\n",
    "for entity_query, relevant_set in relevant_documents.items():\n",
    "    \n",
    "    try:\n",
    "        if entity_query:\n",
    "            res_Boolean = inverted_index[entity_query[0]]\n",
    "            for word in entity_query[1:]:\n",
    "                    res_Boolean = res_Boolean.intersection(inverted_index[word])\n",
    "    except:\n",
    "        res_Boolean = set([])\n",
    "    \n",
    "\n",
    "    ## tfidf top-5 results\n",
    "    #\n",
    "    tfidf_scores = []\n",
    "    for match_doc_id in res_Boolean:\n",
    "        doc_score = 0\n",
    "\n",
    "        for keyword in set(entity_query):\n",
    "\n",
    "            # count the number of occurrence of this keyword in document\n",
    "            t_fd = doc_tokens[match_doc_id].count(keyword)\n",
    "            \n",
    "            tf = 1 + math.log10(t_fd)\n",
    "\n",
    "            # sum over all terms in query AND document\n",
    "            doc_score += (tf * IDF[keyword])\n",
    "            \n",
    "        # append the final document score for comparision\n",
    "        tfidf_scores.append((doc_score,match_doc_id))\n",
    "\n",
    "\n",
    "    tfidf_top5 = set()\n",
    "    for score,doc_id in sorted(tfidf_scores,reverse=True)[:5]:\n",
    "        tfidf_top5.add(doc_id)\n",
    "\n",
    "    tfidf_relevant += len(tfidf_top5.intersection(relevant_set))  \n",
    "        \n",
    "    ## VSM top5 results\n",
    "    \n",
    "    # generating the query vector\n",
    "    # count the number of occurences for each word        \n",
    "    term_freq = Counter(entity_query)\n",
    "    query_vector = np.zeros(vocab_id)\n",
    "\n",
    "    # for each word and its count\n",
    "    for term,count in term_freq.items():\n",
    "        if remove_stopwords == True and term in stopwords.words('english'):\n",
    "            continue\n",
    "        elif term not in vocab_id_table:\n",
    "            continue\n",
    "        \n",
    "        tf = count\n",
    "        # documents are rows and words are columns\n",
    "        query_vector[vocab_id_table[term]] += (tf * IDF[term])\n",
    "\n",
    "    # cosine similairty calculation for each document\n",
    "    cos_similarity = np.zeros(N)\n",
    "\n",
    "    # TODO - optimize this function. Use numpy only.\n",
    "    for idx in res_Boolean:\n",
    "        cos_similarity[idx] = dot(doc_vectors[idx], query_vector)/(norm(doc_vectors[idx])*norm(query_vector))\n",
    "\n",
    "    # gets the top 5 in linear time\n",
    "    top5_index = np.argpartition(cos_similarity, -5)[-5:]\n",
    "    \n",
    "    vsm_top5 = set(top5_index)\n",
    "    vsm_relevant += len(vsm_top5.intersection(relevant_set))\n",
    "    \n",
    "\n",
    "    b= 0.75\n",
    "    k_1 = 1.2\n",
    "    avgdl = Total_document_length/N\n",
    "    \n",
    "    bm25_scores  = []\n",
    "\n",
    "    for match_doc_id in res_Boolean:\n",
    "        bm25_doc_score = 0\n",
    "        D = len(documents[match_doc_id][0].split())\n",
    "\n",
    "        for keyword in set(entity_query):\n",
    "            if remove_stopwords == True and keyword in stopwords.words('english'):\n",
    "                continue\n",
    "            elif keyword not in vocab_id_table:\n",
    "                continue\n",
    "            \n",
    "            # count the number of occurrence of this keyword in document\n",
    "            f_qi_D = doc_tokens[match_doc_id].count(keyword)\n",
    "            # saturation\n",
    "            saturation = f_qi_D * ( k_1 + 1 ) / (f_qi_D + k_1)\n",
    "            # document length normaliztion (B)\n",
    "            B = (1 - b) + ( b * D / avgdl)                \n",
    "            # sum over all terms in query AND document\n",
    "            bm25_doc_score += IDF_BM25[keyword] * saturation / B\n",
    "            \n",
    "        bm25_scores.append((bm25_doc_score,match_doc_id))\n",
    "\n",
    "    bm25_top5 = set()\n",
    "    for score,doc_id in sorted(bm25_scores,reverse=True)[:5]:\n",
    "        bm25_top5.add(doc_id)\n",
    "\n",
    "    bm25_relevant += len(bm25_top5.intersection(relevant_set))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Part Bonus: Evaluation ~~~\n",
      "Metric: Precision @ 5 \n",
      "\n",
      "Calculated with each entity as query, the definitions as relevant documents and the top-5 results as the retreived documents\n",
      "\n",
      "TF-IDF =  0.2140386571719227\n",
      "VSM =  0.1770091556459817\n",
      "BM25 =  0.1686673448626653\n"
     ]
    }
   ],
   "source": [
    "## Lets check and compare the scores:\n",
    "\n",
    "# we are considering 5 retreived results for each query\n",
    "# relevant documents contains the count of queries\n",
    "\n",
    "Total_retreived = len(relevant_documents) * 5\n",
    "\n",
    "# precision is given my relevant retreived / total retreived\n",
    "\n",
    "tfidf_precision = tfidf_relevant/Total_retreived\n",
    "vsm_precision = vsm_relevant/Total_retreived\n",
    "bm25_precision = bm25_relevant/Total_retreived\n",
    "\n",
    "print(\"~~~ Part Bonus: Evaluation ~~~\")\n",
    "\n",
    "print(\"Metric: Precision @ 5\",\"\\n\")\n",
    "print(\"Calculated with each entity as query, the definitions as relevant documents and the top-5 results as the retreived documents\\n\")\n",
    "print(\"TF-IDF = \", tfidf_precision)\n",
    "print(\"VSM = \", vsm_precision)\n",
    "print(\"BM25 = \", bm25_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration Declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** You should fill out your collaboration declarations here.**\n",
    "\n",
    "**Reminder:** You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by filling out the Collaboration Declarations at the bottom of this notebook.\n",
    "\n",
    "Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
