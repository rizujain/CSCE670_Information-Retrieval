{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2020\n",
    "\n",
    "\n",
    "# Homework 3:   Recommender System Practice: Rating Prediction and Top-K Item Recommendation\n",
    "\n",
    "### 100 points [ 6% of your final grade]\n",
    "\n",
    "### Due: April 10, 2020\n",
    "\n",
    "*Goals of this homework:* Understand matrix factorization (MF) using explicit feedback and Bayesian Personalized Ranking (BPR) using implicit feedback for recommendation. Explore different methods for two real-world recommendation senarios: rating prediction and top-K item recommendation.\n",
    "\n",
    "*Submission instructions (eCampus):* To submit your homework, rename this notebook as `UIN_hw3.ipynb`. For example, my homework submission would be something like `555001234_hw3.ipynb`. Submit this notebook via eCampus (look for the homework 3 assignment there). Your notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so). So please run all the cells for us, and then submit.\n",
    "\n",
    "*Late submission policy:* For this homework, you may use as many late days as you like (up to the total late days you have remaining).\n",
    "\n",
    "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
    "\n",
    "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
    "\n",
    "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Matrix Factorization for Rating Prediction (70 points total)\n",
    "\n",
    "In some platforms, such as MovieLens, users express their preference on items using explict feedback like ratings.\n",
    "\n",
    "In this part, you will implement matrix factorization to predict ratings on MovieLens data. After removing users who left less than 20 ratings and movies with less than 20 ratings, the provided dataset has only ~1,200 items and ~500 users. You can also check the title and genres of each movie in *movies_info.csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1a: Load the Data (5 points)\n",
    "\n",
    "Please download the dataset from Piazza. There are about 65,000 ratings in total. We split the rating data into two sets. You will train with 70% of the data (in *train_movie.csv*) and test on the remaining 30% of data (in *test_movie.csv*). Each of train and test files has lines having this format: UserID, MovieID, Rating. \n",
    "\n",
    "First you will need to load the data and store it with any structure you like. Please report the numbers of unique users and movies in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 541\n",
      "num_movies: 1211\n"
     ]
    }
   ],
   "source": [
    "# load the data, then print out the number of\n",
    "# movies and users in each of train and test sets.\n",
    "# Your Code Here...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"./rating prediction dataset/train_movie.csv\")\n",
    "train_data.head()\n",
    "\n",
    "users = train_data['userId'].unique()\n",
    "movies = train_data['movieId'].unique()\n",
    "\n",
    "num_users = len(users)\n",
    "num_movies = len(movies)\n",
    "\n",
    "print(\"num_users:\", num_users)\n",
    "print(\"num_movies:\",num_movies)\n",
    "\n",
    "uid = dict(zip(users,range(0,num_users)))\n",
    "mid = dict(zip(movies,range(0,num_movies)))\n",
    "\n",
    "train_data = train_data.sample(frac=1)\n",
    "train_np = train_data.values\n",
    "np.random.shuffle(train_np)\n",
    "\n",
    "train_samples = int(train_data.shape[0]*0.8)\n",
    "train_80 = train_np[:train_samples,:]\n",
    "cross_20 = train_np[train_samples:,:]\n",
    "\n",
    "mat= np.full((num_users,num_movies),-1)\n",
    "\n",
    "# train data numpy matris\n",
    "td = train_80\n",
    "\n",
    "for i in range(0,td.shape[0]):\n",
    "    mat[uid[td[i,0]],mid[td[i,1]]] = td[i,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1b: Matrix Factorization (40 points)\n",
    "\n",
    "In class, we introduced how matrix factorization works for recommendation. Now it is your term to implement it. There are different methods to obtain the latent factor matrices **P** and **Q**, like gradient descent, Alternating Least Squares (ALS), and so on. Pick one of them and implement your MF model. *You can refer to tutorials and resources online. Remember our **collaboration policy** and you need to inform us of the resources you refer to.* \n",
    "\n",
    "Please report MAE and RMSE of your MF model for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here...\n",
    "# Report Mean Absolute Error and Root Mean Squared Error for test\n",
    "\n",
    "class MF:\n",
    "    def __init__(self, train, hidden=40, epoch=10, lr=0.01, bias=False, r = 0.01):\n",
    "        self.bias = bias\n",
    "        self.train = train\n",
    "        self.mask = 1.0 * (train >= 0)\n",
    "        self.num_train = np.sum(self.mask)\n",
    "        self.num_user, self.num_item = train.shape\n",
    "        self.hidden = hidden\n",
    "        self.regularization = r\n",
    "\n",
    "        if self.bias:\n",
    "            self.global_bias = np.sum(train) / np.sum(self.mask)\n",
    "            self.user_bias = np.sum((train - self.global_bias) * self.mask, axis=1) / np.sum(self.mask, axis=1)\n",
    "            self.item_bias = np.sum((train - self.global_bias) * self.mask, axis=0) / np.sum(self.mask, axis=0)\n",
    "        else:\n",
    "            self.user_bias = np.zeros(self.num_user)\n",
    "            self.item_bias = np.zeros(self.num_item)\n",
    "            self.global_bias = 0.0\n",
    "\n",
    "        self.epoch = epoch\n",
    "\n",
    "        self.sample_row, self.sample_col = np.where(train>=0)\n",
    "        self.n_samples = len(self.sample_row)\n",
    "        print(self.n_samples)\n",
    "        self.lr = lr\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        # initialize\n",
    "        self.P = np.random.random((self.num_user, self.hidden))\n",
    "        self.Q = np.random.random((self.num_item, self.hidden))\n",
    "\n",
    "        for itr in range(self.epoch):\n",
    "            self.training_indices = np.arange(self.n_samples)\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            for idx in self.training_indices:\n",
    "                u = self.sample_row[idx]\n",
    "                i = self.sample_col[idx]\n",
    "                rating = self.train[u, i]\n",
    "                e = rating - self.P[u, :].dot(self.Q[i, :].T) - self.global_bias - self.item_bias[i] - self.user_bias[u]\n",
    "                self.P[u, :] += self.lr * (e * self.Q[i, :] - self.regularization * self.P[u, :])\n",
    "                self.Q[i, :] += self.lr * (e * self.P[u, :] - self.regularization * self.Q[u, :])\n",
    "\n",
    "            Rec = self.P.dot(self.Q.T) + self.global_bias + self.item_bias + self.user_bias.reshape((-1, 1))\n",
    "            error = np.sqrt(np.sum(np.square(Rec * self.mask - self.train * self.mask)) / self.num_train)\n",
    "            if itr % 10 == 0:\n",
    "                print('iters={0}, RMSE={1}'.format(itr, error))\n",
    "        return self.P, self.Q, (self.P.dot(self.Q.T) + self.global_bias + self.item_bias + self.user_bias.reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt import space_eval\n",
    "\n",
    "# We want to minimize loss i.e. negative of accuracy\n",
    "def optimize(hyperparam):\n",
    "    print(hyperparam)\n",
    "\n",
    "    mf = MF(mat, hidden=hyperparam['hiddens'], lr=hyperparam['lrs'], epoch=25,r = hyperparam['regs'])\n",
    "    P_mf, Q_mf, Rec_mf = mf.fit()\n",
    "    \n",
    "    RMSE = 0\n",
    "\n",
    "    for row in range(cross_20.shape[0]):\n",
    "        score = P_mf[uid[cross_20[row,0]],:].dot(np.transpose(Q_mf[mid[cross_20[row,1]],:]))\n",
    "        RMSE += np.square(cross_20[row,2]-score)\n",
    "\n",
    "    RMSE = RMSE/cross_20.shape[0]\n",
    "    RMSE = np.sqrt(RMSE)\n",
    "    \n",
    "    print(\"RMSE: \",RMSE)\n",
    "    \n",
    "    return({\"status\": STATUS_OK, \"loss\": RMSE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hiddens': 12, 'lrs': 0.003, 'regs': 0.1}                                                                             \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.0695564737218985                                                                                       \n",
      "iters=10, RMSE=0.8465132335779115                                                                                      \n",
      "iters=20, RMSE=0.8227690202137479                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "0.9093528831374047                                                                                                     \n",
      "{'hiddens': 12, 'lrs': 0.003, 'regs': 0.5}                                                                             \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.161194328797633                                                                                        \n",
      "iters=10, RMSE=0.9791310938169874                                                                                      \n",
      "iters=20, RMSE=0.9721426491750775                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "1.0365067218298352                                                                                                     \n",
      "{'hiddens': 8, 'lrs': 0.001, 'regs': 0.05}                                                                             \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.5628045719351464                                                                                       \n",
      "iters=10, RMSE=0.9383044660794845                                                                                      \n",
      "iters=20, RMSE=0.8740629536076217                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "0.9196328906058785                                                                                                     \n",
      "{'hiddens': 10, 'lrs': 0.003, 'regs': 0.1}                                                                             \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.1200806243492527                                                                                       \n",
      "iters=10, RMSE=0.8500444966342777                                                                                      \n",
      "iters=20, RMSE=0.8298296705745135                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "0.9067109544407358                                                                                                     \n",
      "{'hiddens': 5, 'lrs': 0.001, 'regs': 0.1}                                                                              \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=2.097838849797323                                                                                        \n",
      "iters=10, RMSE=1.0252470879398532                                                                                      \n",
      "iters=20, RMSE=0.906360182764606                                                                                       \n",
      "RMSE:                                                                                                                  \n",
      "0.9447261315181932                                                                                                     \n",
      "{'hiddens': 10, 'lrs': 0.003, 'regs': 0.5}                                                                             \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.2516551006191934                                                                                       \n",
      "iters=10, RMSE=0.9856458112736195                                                                                      \n",
      "iters=20, RMSE=0.9747883390542011                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "1.0338923514206602                                                                                                     \n",
      "{'hiddens': 5, 'lrs': 0.001, 'regs': 0.1}                                                                              \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=2.06625506314186                                                                                         \n",
      "iters=10, RMSE=1.0237531663094097                                                                                      \n",
      "iters=20, RMSE=0.9057589739133175                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "0.9433711616940234                                                                                                     \n",
      "{'hiddens': 12, 'lrs': 0.001, 'regs': 0.01}                                                                            \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.2175303659272094                                                                                       \n",
      "iters=10, RMSE=0.9121544385130803                                                                                      \n",
      "iters=20, RMSE=0.8653356200599286                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "0.9143144725611737                                                                                                     \n",
      "{'hiddens': 8, 'lrs': 0.01, 'regs': 0.5}                                                                               \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.0992530346117364                                                                                       \n",
      "iters=10, RMSE=0.9678664627981121                                                                                      \n",
      "iters=20, RMSE=0.9585461283062064                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "1.0528336511752294                                                                                                     \n",
      "{'hiddens': 10, 'lrs': 0.001, 'regs': 0.05}                                                                            \n",
      "36225                                                                                                                  \n",
      "iters=0, RMSE=1.3283460987400013                                                                                       \n",
      "iters=10, RMSE=0.9228447176144092                                                                                      \n",
      "iters=20, RMSE=0.8688024700439686                                                                                      \n",
      "RMSE:                                                                                                                  \n",
      "0.9161326212579192                                                                                                     \n",
      "100%|████████████████████████████████████████████████| 10/10 [05:59<00:00, 36.30s/trial, best loss: 0.9067109544407358]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define search space for hyper-parameters\n",
    "space = {\n",
    "    'hiddens': hp.choice('hiddens', [5,8,10,12]),\n",
    "    'lrs': hp.choice('lrs', [0.001,0.003,0.01]),\n",
    "    'regs': hp.choice('regs', [0.01,0.05,0.1,0.5]),\n",
    "}\n",
    "\n",
    "trials_mf = Trials()\n",
    "\n",
    "# Find the best hyperparameters\n",
    "best = fmin(\n",
    "        optimize,\n",
    "        space,\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials_mf,\n",
    "        max_evals=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45282\n",
      "iters=0, RMSE=1.0971005329751187\n",
      "iters=10, RMSE=0.8495275012336072\n",
      "iters=20, RMSE=0.8341123325234236\n",
      "iters=30, RMSE=0.8212619901816604\n",
      "iters=40, RMSE=0.8074849482808698\n",
      "iters=50, RMSE=0.7919864123693288\n",
      "iters=60, RMSE=0.7757768800440233\n",
      "iters=70, RMSE=0.7611068410448105\n",
      "iters=80, RMSE=0.7467851450938148\n",
      "iters=90, RMSE=0.7345240942228494\n"
     ]
    }
   ],
   "source": [
    "td_final = train_data.values\n",
    "mat_train= np.full((num_users,num_movies),-1)\n",
    "\n",
    "\n",
    "for i in range(0,td_final.shape[0]):\n",
    "    mat_train[uid[td_final[i,0]],mid[td_final[i,1]]] = td_final[i,2]\n",
    "    \n",
    "# best hyperparamters found by hyperparamter tuning \n",
    "\n",
    "best_params = space_eval(space,best)\n",
    "\n",
    "mf = MF(mat_train, hidden=best_params['hiddens'], lr=best_params['lrs'], epoch=100,r = best_params['regs'])\n",
    "P_mf, Q_mf, Rec_mf = mf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7083750094272993\n",
      "0.9173159917603063\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./rating prediction dataset/test_movie.csv\")\n",
    "test_data.head()\n",
    "\n",
    "MAE = 0\n",
    "RMSE = 0\n",
    "\n",
    "y_pred_mf = np.zeros(test_data.shape[0])\n",
    "\n",
    "idx = 0\n",
    "for row in test_data.itertuples(index=False):\n",
    "    score = P_mf[uid[row[0]],:].dot(np.transpose(Q_mf[mid[row[1]],:]))\n",
    "    y_pred_mf[idx] = score\n",
    "    idx +=1\n",
    "    MAE += abs(row[2]-score)\n",
    "    RMSE += np.square(row[2]-score)\n",
    "\n",
    "MAE = MAE/test_data.shape[0]\n",
    "RMSE = RMSE/test_data.shape[0]\n",
    "RMSE = np.sqrt(RMSE)\n",
    "\n",
    "print(MAE)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE = 0.7083\n",
    "#### RMSE = 0.9173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which method did you use to obtain **P** and **Q**? What are the advantages and disadvantages of the method you pick? *provide a brief (1-2 paragraph) discussion based on these questions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used stochastic gradient descent for matrix factorization. My inclination towards SGD was because of sources suggesting better results using it [Here: http://cs229.stanford.edu/proj2014/Christopher%20Aberger,%20Recommender.pdf]\n",
    "\n",
    "The improved accuracy however comes at the expanse of training time which is much more compared to ALS. SGD also has a tendency to overfit much and hence a wider hyperparamter space needs to be searched for. Which further worsens the already slow compute time exponentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1c: Improve MF (25 points)\n",
    "\n",
    "Given your results in the previous part, can you do better? For this last part you should report on your best attempt at improving MAE and RMSE. Provide code, results, plus a brief discussion on your approach. Hints: You may consider using the title or genres information, trying other algorithms, designing a hybrid system or considering a neighborhood like this paper [Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model](https://www.cs.rochester.edu/twiki/pub/Main/HarpSeminar/Factorization_Meets_the_Neighborhood-_a_Multifaceted_Collaborative_Filtering_Model.pdf). *You can do anything you like to improve MAE and RMSE.*\n",
    "\n",
    "You will get full marks for this part if you get better results than your MF results (of course we will also judge whether what you do here is reasonable or not). You will get partial marks for a reasonable effort even if you do not improve your MF results. Additionally, you will get 5 points as bonus if your model performs the best among the whole class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get them movie categories shall we?\n",
    "from itertools import chain\n",
    "\n",
    "file1 = open(\"./rating prediction dataset/movies_info.csv\", 'r') \n",
    "Lines = file1.readlines() \n",
    "\n",
    "categories = set()\n",
    "genre = {}\n",
    "year = {}\n",
    "\n",
    "count = 0\n",
    "for line in Lines:\n",
    "    if count == 0:\n",
    "        count = 1\n",
    "        continue\n",
    "\n",
    "    mov = line.split(\"\t\")\n",
    "    if len(mov)>1:\n",
    "        mov[2] = mov[2].strip()\n",
    "        genre[int(mov[0])] = mov[2].split(\"|\")\n",
    "        year[int(mov[0])] = int(mov[1][-5:-1])\n",
    "\n",
    "\n",
    "categories = set(chain(*genre.values()))\n",
    "\n",
    "cat = {}\n",
    "idx = 0\n",
    "for category in categories:\n",
    "    cat[category] = idx\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here...\n",
    "# Report Mean Absolute Error and Root Mean Squared Error for test\n",
    "\n",
    "# let us create training and testing datasets from the user vectors and movie vectors\n",
    "factors = P_mf.shape[1]\n",
    "features = factors*2 + 22\n",
    "\n",
    "x_train = np.zeros((train_data.shape[0],features))\n",
    "y_train = np.zeros((train_data.shape[0],))\n",
    "\n",
    "for i in range(train_data.shape[0]):\n",
    "    _user = uid[train_data.values[i,0]]\n",
    "    _movie = mid[train_data.values[i,1]]\n",
    "    x_train[i,:factors] = P_mf[_user,:]\n",
    "    x_train[i,factors:factors*2] = Q_mf[_movie,:]\n",
    "    x_train[i,-2] = year[_movie]\n",
    "    x_train[i,-1] = P_mf[_user,:].dot(np.transpose(Q_mf[_movie,:]))\n",
    "\n",
    "    for c in genre[_movie]:\n",
    "        x_train[i,factors*2+cat[c]] = 1\n",
    "\n",
    "    y_train[i] = train_data.values[i,2]\n",
    "\n",
    "    \n",
    "x_test = np.zeros((test_data.shape[0],features))\n",
    "y_test = np.zeros((test_data.shape[0],))\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    _user = uid[test_data.values[i,0]]\n",
    "    _movie = mid[test_data.values[i,1]]\n",
    "    x_test[i,:factors] = P_mf[_user,:]\n",
    "    x_test[i,factors:factors*2] = Q_mf[_movie,:]\n",
    "    x_test[i,-2] = year[_movie]\n",
    "    x_test[i,-1] = P_mf[_user,:].dot(np.transpose(Q_mf[_movie,:]))\n",
    "    \n",
    "    for c in genre[_movie]:\n",
    "        x_test[i,factors*2+cat[c]] = 1\n",
    "\n",
    "    y_test[i] = test_data.values[i,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def optimize_xgb(hyperparam):\n",
    "    print(hyperparam)\n",
    "\n",
    "    split_at = int(x_train.shape[0] * 0.8)\n",
    "    opt_x_train = x_train[:split_at,:]\n",
    "    opt_y_train = y_train[:split_at]\n",
    "    \n",
    "    opt_x_val = x_train[split_at:,:]\n",
    "    opt_y_val = y_train[split_at:]\n",
    "    \n",
    "    model = XGBRegressor(**hyperparam)\n",
    "    model.fit(opt_x_train,opt_y_train)\n",
    "    \n",
    "    opt_y_pred = model.predict(opt_x_val)\n",
    "    \n",
    "    opt_rmse = np.sqrt(np.mean(np.square(opt_y_pred-opt_y_val)))\n",
    "\n",
    "    print(\"RMSE:\",opt_rmse)\n",
    "    \n",
    "    return({\"status\": STATUS_OK, \"loss\": opt_rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.1, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 100, 'subsample': 0.8569738004137474}\n",
      "[22:50:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE:                                                                                                                  \n",
      "0.7477775527082361                                                                                                     \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 100, 'subsample': 0.9575782580855137}\n",
      "[22:51:21] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE:                                                                                                                  \n",
      "0.7391581623266475                                                                                                     \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.2, 'max_depth': 15, 'min_child_weight': 5, 'n_estimators': 100, 'subsample': 0.9040707831640572}\n",
      "[22:51:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE:                                                                                                                  \n",
      "0.7889705516184828                                                                                                     \n",
      "{'colsample_bytree': 0.6000000000000001, 'learning_rate': 0.15000000000000002, 'max_depth': 10, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.9579768568422744}\n",
      "[22:52:29] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE:                                                                                                                  \n",
      "0.7527448221544346                                                                                                     \n",
      "{'colsample_bytree': 0.3, 'learning_rate': 0.2, 'max_depth': 12, 'min_child_weight': 4, 'n_estimators': 100, 'subsample': 0.8517717611386808}\n",
      "[22:52:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE:                                                                                                                  \n",
      "0.8088103896961356                                                                                                     \n",
      "100%|██████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.05s/trial, best loss: 0.7391581623266475]\n"
     ]
    }
   ],
   "source": [
    "# XGB parameters\n",
    "space_xgb = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "}\n",
    "\n",
    "trials_xgb = Trials()\n",
    "\n",
    "# Find the best hyperparameters\n",
    "best_xgb = fmin(\n",
    "        optimize_xgb,\n",
    "        space_xgb,\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials_xgb,\n",
    "        max_evals=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:53:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 0.9398960787812505\n",
      "MAE: 0.7116150245555766\n"
     ]
    }
   ],
   "source": [
    "model_opt = XGBRegressor(colsample_bytree= 0.7, learning_rate= 0.1, max_depth= 7, min_child_weight= 7, n_estimators= 100, subsample= 0.97)\n",
    "model_opt.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model_opt.predict(x_test)\n",
    "\n",
    "rmse = np.sqrt(np.mean(np.square(y_pred-y_test)))\n",
    "mae = np.mean(np.abs(y_pred-y_test))\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"MAE:\",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7057971994236139\n",
      "RMSE: 0.9234126901026305\n"
     ]
    }
   ],
   "source": [
    "y_pred_2 = y_pred + y_pred_mf\n",
    "y_pred_2 /= 2\n",
    "rmse = np.sqrt(np.mean(np.square(y_pred_2-y_test)))\n",
    "mae = np.mean(np.abs(y_pred_2-y_test))\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try ensemble methods\n",
    "import surprise\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = pd.read_csv(\"./rating prediction dataset/train_movie.csv\")\n",
    "\n",
    "rawTrain,rawholdout = train_test_split(df_train, test_size=0.25)\n",
    "reader = surprise.Reader(rating_scale=(1,5)) \n",
    "\n",
    "#into surprise:\n",
    "data = surprise.Dataset.load_from_df(rawTrain,reader)\n",
    "holdout = surprise.Dataset.load_from_df(rawholdout,reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "testset = holdout.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros((rawholdout.shape[0],4))\n",
    "y_train = np.zeros(rawholdout.shape[0])\n",
    "\n",
    "i=0\n",
    "for test in testset:\n",
    "    y_train[i]=test[2]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\Anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:248: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "RMSE: 0.8999\n"
     ]
    }
   ],
   "source": [
    "sim_options = sim_options = {'name': 'cosine',\n",
    "               'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "collabKNN = surprise.KNNWithMeans(k=40,sim_options=sim_options) #try removing sim_options. You'll find memory errors. \n",
    "\n",
    "collabKNN.fit(trainset)\n",
    "predictionsKNN = collabKNN.test(testset)\n",
    "surprise.accuracy.rmse(predictionsKNN,verbose=True)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsKNN:\n",
    "    x_train[i,0] = prediction.est\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8946\n"
     ]
    }
   ],
   "source": [
    "funkSVD = surprise.prediction_algorithms.matrix_factorization.SVD(n_factors=50,n_epochs=30,biased=True)\n",
    "funkSVD.fit(trainset)\n",
    "predictionsSVD = funkSVD.test(testset)\n",
    "surprise.accuracy.rmse(predictionsSVD,verbose=True)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsSVD:\n",
    "    x_train[i,1] = prediction.est\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9226\n"
     ]
    }
   ],
   "source": [
    "coClus = surprise.prediction_algorithms.co_clustering.CoClustering(n_cltr_u=4,n_cltr_i=4,n_epochs=25) \n",
    "coClus.fit(trainset)\n",
    "predictionsCoClus = coClus.test(testset)\n",
    "surprise.accuracy.rmse(predictionsCoClus,verbose=True)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsCoClus:\n",
    "    x_train[i,2] = prediction.est\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8980\n"
     ]
    }
   ],
   "source": [
    "slopeOne = surprise.prediction_algorithms.slope_one.SlopeOne()\n",
    "slopeOne.fit(trainset)\n",
    "predictionsSlope = slopeOne.test(testset)\n",
    "surprise.accuracy.rmse(predictionsSlope,verbose=True)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsSlope:\n",
    "    x_train[i,3] = prediction.est\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./rating prediction dataset/test_movie.csv\")\n",
    "test = surprise.Dataset.load_from_df(test_data,reader)\n",
    "\n",
    "TEST_trainset = test.build_full_trainset()\n",
    "TEST_testset = TEST_trainset.build_testset()\n",
    "\n",
    "x_test = np.zeros((test_data.shape[0],4))\n",
    "y_test = np.zeros(test_data.shape[0])\n",
    "\n",
    "i=0\n",
    "for test in TEST_testset:\n",
    "    y_test[i]=test[2]\n",
    "    i += 1\n",
    "\n",
    "predictionsKNN = collabKNN.test(TEST_testset)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsKNN:\n",
    "    x_test[i,0] = prediction.est\n",
    "    i += 1\n",
    "\n",
    "predictionsSVD = funkSVD.test(TEST_testset)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsSVD:\n",
    "    x_test[i,1] = prediction.est\n",
    "    i += 1\n",
    "\n",
    "predictionsCoClus = coClus.test(TEST_testset)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsCoClus:\n",
    "    x_test[i,2] = prediction.est\n",
    "    i += 1\n",
    "\n",
    "predictionsSlope = slopeOne.test(TEST_testset)\n",
    "\n",
    "i = 0\n",
    "for prediction in predictionsSlope:\n",
    "    x_test[i,3] = prediction.est\n",
    "    i += 1\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8799290817017825\n",
      "MAE: 0.6773006644638268\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(np.mean(np.square(y_pred-y_test)))\n",
    "mae = np.mean(np.abs(y_pred-y_test))\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"MAE:\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain what you do to improve the recommendation in 1-2 paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 1 - Using Content information with features\n",
    "I used the movie release year and genre as features alongside the user and movie feature vectors from the matrix factorization algorithm in a random forest regression model. I did not see any imporvement in that model though.\n",
    "\n",
    "\n",
    "#### Attempt 2 - Ensemble ratings from multiple models (KNN + SVD + Clustering + slope one)\n",
    "I used 4 different models and learn predictions from that. These predictions are then used to train a linear regression model which will learn parameters giving a weighted average.\n",
    "\n",
    "#### MAE: 0.6773006644638268 \n",
    "(using mf: 0.7083750094272993)\n",
    "#### RMSE: 0.8799290817017825 \n",
    "(using mf: 0.9173159917603063)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Bayesian Personalized Ranking (BPR) for Top-K Item Recommendation (30 points)\n",
    "\n",
    "Compared with rating prediction in part 1, a more popular scenario recently is personalized top-K item ranking for each user based on the user's implicit feedback. Examples include ranking videos on YouTube and ranking products on Aamzon. In practice, users tend to provide implicit feedback (e.g., the user clicked a product URL on Amazon or played a video on YouTube) rather than explicit feedback (e.g., ratings or reviews) in most cases.\n",
    "\n",
    "In this part, you will experiment with Bayesian Personalized Ranking (BPR) to rank items on a [Spotify Playlist Recommendation Dataset](http://people.tamu.edu/~yunhe/pubs/AttListCIKM2019.pdf). If a user ever followed a playlist, this interaction is treated as an implicit feedback. In our sampled dataset, there are ~10,000 users and ~7,000 playlists.\n",
    "\n",
    "BPR can generate scores of items for each user. You should rank all items based on the scores for each user and evaluate the ranking performance.\n",
    "\n",
    "For example, if user 0 has two interacted playlists 23, 78 in test.txt. If the top-10 playlists for user 0 returned by BPR is [12,45,78,34,23,90,134,33,46,9], then the precision@10 for user 0 is 0.2 because the two playlists in test.txt are recommended in top-10: 2/10=0.2. Please report NDCG@10 in this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Please download the dataset from Piazza. There are about 90,000 interactions in total, which are split into training.txt, validation.txt and text.txt. You will train on train.txt, tune hyperparameters on validation.txt and report final result on test.txt in terms of NDCG@10. \n",
    "\n",
    "Each of the train and test files has lines having this format: UserID, PlaylistID, 1.0. \n",
    "\n",
    "First you will need to load the data and store it with any structure you like. Please report the numbers of unique users and movies in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 10183\n",
      "Number of unique playlists: 7787\n"
     ]
    }
   ],
   "source": [
    "# load the data, then print out the number of\n",
    "# playlists and users in each of train and test sets.\n",
    "# Your Code Here...\n",
    "from collections import defaultdict \n",
    "from implicit import bpr\n",
    "import scipy.sparse as sp\n",
    "\n",
    "df_train = pd.read_csv(\"./top-K recommendation dataset/train.txt\",sep=\"\\t\",header=None)\n",
    "\n",
    "users = df_train[0].unique()\n",
    "plays = df_train[1].unique()\n",
    "\n",
    "num_users = len(users)\n",
    "num_plays = len(plays)\n",
    "\n",
    "print(\"Number of unique users:\", num_users)\n",
    "print(\"Number of unique playlists:\",num_plays)\n",
    "\n",
    "df_train = df_train.sample(frac=1)\n",
    "\n",
    "mat_bpr = np.full((num_users,num_plays),0)\n",
    "\n",
    "# train data numpy matris\n",
    "td = df_train.values\n",
    "td = td.astype(int)\n",
    "\n",
    "for i in range(0,td.shape[0]):\n",
    "    mat_bpr[td[i,0],td[i,1]] = td[i,2]\n",
    "\n",
    "\n",
    "# sparse matrix for bpr in implicit package\n",
    "mat_coo = sp.csr_matrix(mat_bpr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"./top-K recommendation dataset/validation.txt\",sep=\"\\t\",header=None)\n",
    "df_test = pd.read_csv(\"./top-K recommendation dataset/test.txt\",sep=\"\\t\",header=None)\n",
    "\n",
    "\n",
    "recommend_val  = defaultdict(list)\n",
    "\n",
    "for row in df_val.itertuples():\n",
    "    recommend_val[row[1]].append(row[2])\n",
    "    \n",
    "recommend_test = defaultdict(list)\n",
    "\n",
    "for row in df_test.itertuples():\n",
    "    recommend_test[row[1]].append(row[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR by Using Package\n",
    "\n",
    "Compared with MF, BPR is more complicated to implement. In this part, you can use a BPR package to experiment with top-K item recommendation. Some good packages include https://github.com/benfred/implicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ndcg(topk,match):\n",
    "    rel = []\n",
    "    for k in topk:\n",
    "        if k in match:\n",
    "            rel.append(1)\n",
    "        else:\n",
    "            rel.append(0)\n",
    "\n",
    "    dcg = 0\n",
    "    for i in range(1,11):\n",
    "        dcg += rel[i-1]/math.log(1+i)\n",
    "    \n",
    "    idcg = 0\n",
    "    rel = sorted(rel,reverse=True)\n",
    "    for i in range(1,11):\n",
    "        idcg += rel[i-1]/math.log(1+i)\n",
    "    \n",
    "    return dcg/(idcg+1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code to call other BPR packages for top-K recommendation.\n",
    "# Report average NDCG@10 for all users on test.txt\n",
    "\n",
    "def optimize_bpr(hyperparam):\n",
    "    print(hyperparam)\n",
    "    \n",
    "    model2 = bpr.BayesianPersonalizedRanking(**hyperparam)\n",
    "    model2.fit(mat_coo)    \n",
    "\n",
    "    avg_ndcg = 0\n",
    "    count = 0\n",
    "    \n",
    "    for user,playlists in recommend_val.items():\n",
    "        rec = model2.recommend(user,mat_coo.T.tocsr(),10)\n",
    "        rec = [i[0] for i in rec]\n",
    "        avg_ndcg += ndcg(rec,playlists)\n",
    "        count += 1\n",
    "\n",
    "    avg_ndcg/= count\n",
    "    \n",
    "    print(\"NDCG: \",avg_ndcg)\n",
    "    \n",
    "    return({\"status\": STATUS_OK, \"loss\": -1 * avg_ndcg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'factors': 50, 'learning_rate': 0.03, 'regularization': 0.05}                                                         \n",
      "  0%|                                                                           | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5b761b5096463a8baa46773033c29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.10973048281755975                                                                                                    \n",
      "{'factors': 100, 'learning_rate': 0.01, 'regularization': 0.05}                                                        \n",
      " 10%|████▋                                          | 1/10 [00:15<02:16, 15.19s/trial, best loss: -0.10973048281755975]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15b5ea701b14270b18657234e06b46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.05852117250036404                                                                                                    \n",
      "{'factors': 50, 'learning_rate': 0.01, 'regularization': 0.005}                                                        \n",
      " 20%|█████████▍                                     | 2/10 [00:32<02:06, 15.77s/trial, best loss: -0.10973048281755975]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d505509fad24d35aeba1db779c34fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.12420095848448141                                                                                                    \n",
      "{'factors': 50, 'learning_rate': 0.01, 'regularization': 0.05}                                                         \n",
      " 30%|██████████████                                 | 3/10 [00:49<01:53, 16.19s/trial, best loss: -0.12420095848448141]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648fe04a96d14bcd91b842bd91ea857d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.06800318527016509                                                                                                    \n",
      "{'factors': 100, 'learning_rate': 0.03, 'regularization': 0.005}                                                       \n",
      " 40%|██████████████████▊                            | 4/10 [01:06<01:38, 16.36s/trial, best loss: -0.12420095848448141]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb6fed7c7fc409188a04cc4454443c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.12682503764145006                                                                                                    \n",
      "{'factors': 50, 'learning_rate': 0.01, 'regularization': 0.01}                                                         \n",
      " 50%|███████████████████████▌                       | 5/10 [01:23<01:22, 16.52s/trial, best loss: -0.12682503764145006]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcf78da200f48f981380774027027f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.124900558398552                                                                                                      \n",
      "{'factors': 100, 'learning_rate': 0.01, 'regularization': 0.05}                                                        \n",
      " 60%|████████████████████████████▏                  | 6/10 [01:39<01:06, 16.52s/trial, best loss: -0.12682503764145006]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d643641a150484388c795721b691bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.05483024104878363                                                                                                    \n",
      "{'factors': 50, 'learning_rate': 0.03, 'regularization': 0.01}                                                         \n",
      " 70%|████████████████████████████████▉              | 7/10 [01:56<00:49, 16.58s/trial, best loss: -0.12682503764145006]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234253b222c94b7f8a23ae0690832ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.12314794797990702                                                                                                    \n",
      "{'factors': 100, 'learning_rate': 0.01, 'regularization': 0.005}                                                       \n",
      " 80%|█████████████████████████████████████▌         | 8/10 [02:12<00:33, 16.51s/trial, best loss: -0.12682503764145006]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbc089ed3d94faaadae60db0474a4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.12205634255748887                                                                                                    \n",
      "{'factors': 50, 'learning_rate': 0.03, 'regularization': 0.005}                                                        \n",
      " 90%|██████████████████████████████████████████▎    | 9/10 [02:29<00:16, 16.54s/trial, best loss: -0.12682503764145006]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bec9afbd044cc581eed7de3ca51c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:                                                                                                                  \n",
      "0.1205188646607641                                                                                                     \n",
      "100%|██████████████████████████████████████████████| 10/10 [02:46<00:00, 16.59s/trial, best loss: -0.12682503764145006]\n"
     ]
    }
   ],
   "source": [
    "# XGB parameters\n",
    "space_bpr = {\n",
    "    'factors':    hp.choice('factors ', [50,100]),\n",
    "    'learning_rate':        hp.choice('learning_rate', [0.01,0.03]),\n",
    "    'regularization': hp.choice('regularization', [0.005,0.01,0.05]),\n",
    "}\n",
    "\n",
    "trials_bpr = Trials()\n",
    "\n",
    "# Find the best hyperparameters\n",
    "best_bpr = fmin(\n",
    "        optimize_bpr,\n",
    "        space_bpr,\n",
    "        algo=tpe.suggest,\n",
    "        trials=trials_bpr,\n",
    "        max_evals=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for bpr:\n",
      "{'factors': 100, 'learning_rate': 0.03, 'regularization': 0.005}\n"
     ]
    }
   ],
   "source": [
    "bpr_hyper = space_eval(space_bpr, best_bpr)\n",
    "print(\"Best hyperparameters for bpr:\")\n",
    "print(bpr_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have the best parameters\n",
    "# add validation to our training data\n",
    "\n",
    "for user in recommend_val:\n",
    "    for playlist in recommend_val[user]:\n",
    "        mat_bpr[user,playlist] = 1\n",
    "\n",
    "# sparse matrix for bpr in implicit package\n",
    "mat_coo = sp.csr_matrix(mat_bpr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619698232a1b4534ae36b21df33cb9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test NDCG:  0.12712006783311303\n"
     ]
    }
   ],
   "source": [
    "#train and report testing NDCG\n",
    "\n",
    "model_final = bpr.BayesianPersonalizedRanking(**bpr_hyper)\n",
    "model_final.fit(mat_coo)    \n",
    "\n",
    "avg_ndcg = 0\n",
    "count = 0\n",
    "\n",
    "for user,playlists in recommend_test.items():\n",
    "    rec = model_final.recommend(user,mat_coo.T.tocsr(),10)\n",
    "    rec = [i[0] for i in rec]\n",
    "    avg_ndcg += ndcg(rec,playlists)\n",
    "    count += 1\n",
    "\n",
    "avg_ndcg/= count\n",
    "\n",
    "print(\"Test NDCG: \",avg_ndcg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NDCG:    0.1271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you collaborated with anyone (see Collaboration policy at the top of this homework), you can put your collaboration declarations here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imported recdemo MF and made modifictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
